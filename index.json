[{"content":"mllint is compiled for Linux, MacOS and Windows, both 64 and 32 bit x86 (MacOS 64-bit only), as well as 64-bit ARM on Linux and MacOS (Apple M1).\nmllint is published to PyPI, so it can be installed globally or in your current environment using pip:\npip install --upgrade mllint Alternatively, to add mllint to an existing project, if your project uses Poetry for its dependencies:\npoetry add --dev mllint Or if your project uses Pipenv:\npipenv install --dev mllint Tools mllint has a soft dependency on several Python tools that it uses for its analysis. While mllint will recommend that you place these tools in your project\u0026rsquo;s development dependencies, these tools are listed as optional dependencies of mllint and can be installed along with mllint using:\npip install --upgrade mllint[tools] Docker There are also mllint Docker containers available on Docker Hub at bvobart/mllint for Python 3.6, 3.7, 3.8 and 3.9. These may particularly be helpful when running mllint in CI environments, such as Gitlab CI or Github Actions. See the Docker Hub for a full list of available tags that can be used.\nThe Docker containers require that you mount the folder with your project onto the container as a volume on /app. Here is an example of how to use this Docker container, assuming that your project is in the current folder. Replace $(pwd) with the full path to your project folder if it is somewhere else.\ndocker run -it --rm -v $(pwd):/app bvobart/mllint:latest ","permalink":"http://bvobart.github.io/mllint/docs/installation/","summary":"mllint is compiled for Linux, MacOS and Windows and is published to \u003ca href=\"https://pypi.org/project/mllint/\"\u003ePyPI\u003c/a\u003e, so it can be installed using \u003ccode\u003epip install -U mllint\u003c/code\u003e Alternatively, use one of the Docker containers at \u003ccode\u003ebvobart/mllint\u003c/code\u003e","title":"Installation"},{"content":"mllint is designed to be used both on your personal computer as well as on CI systems. So, open a terminal in your project folder and run one of the following commands, or add it to your project\u0026rsquo;s CI script.\nTo run mllint on the project in the current folder, simply run:\nmllint To run mllint on a project in another folder, simply run:\nmllint path/to/my-ml-project mllint will analyse your project and create a Markdown-formatted report of its analysis. By default, this will be pretty printed to your terminal.\nIf you instead prefer to export the raw Markdown text to a file, which may be particularly useful when running on CI, the --output or -o flag and provide a filename. mllint does not overwrite the destination file if it already exists, unless --force or -f is used. For example:\nmllint --output report.md Using - (a dash) as the filename prints the raw Markdown directly to your terminal:\nmllint -o - In CI scripts, such raw markdown output (whether as a file or printed to the standard output) can be used to e.g. make comments on pull/merge requests or create Wiki pages on your repository.\nSee this example-report.md for an example of a report that mllint generates, or explore those generated for the example projects.\nOf course, feel free to explore mllint help for more information about its commands and to discover additional flags that can be used.\nLinters, Categories and Rules mllint analyses your project by evaluating several categories of linting rules. Each category, as well as each rule, has a \u0026lsquo;slug\u0026rsquo;, i.e., a lowercased piece of text with dashes or slashes for spaces, e.g., code-quality/pylint/no-issues. This slug identifies a rule and is often (if not always) displayed next to the category or rule that it references.\nTo list all available (implemented) categories and linting rules, run:\nmllint list all To list all enabled linting rules, run (optionally providing the path to the project\u0026rsquo;s folder):\nmllint list enabled By default, all of mllint\u0026rsquo;s rules are enabled. See Configuration to learn how to selectively disable certain rules.\nTo learn more about a certain rule or category, use mllint describe along with the slug of the category or rule:\n# Describe the Version Control category. This will also list the rules that it checks. mllint describe version-control # Use the exact slug of a rule to describe one rule, # e.g., the rule on DVC usage in the Version Control category mllint describe version-control/data/dvc # Use a partial slug to describe all rules whose slug starts with this snippet,  # e.g., all rules about version controlling data mllint describe version-control/data Custom linting rules It is also possible to define your own custom linting rules by implementing a script or program that mllint will run while performing its analysis. These custom rules need to be defined in mllint\u0026rsquo;s configuration. For more information on how to do this, see mllint describe custom.\n","permalink":"http://bvobart.github.io/mllint/docs/usage/","summary":"mllint is compiled for Linux, MacOS and Windows and is published to \u003ca href=\"https://pypi.org/project/mllint/\"\u003ePyPI\u003c/a\u003e, so it can be installed using \u003ccode\u003epip install -U mllint\u003c/code\u003e Alternatively, use one of the Docker containers at \u003ccode\u003ebvobart/mllint\u003c/code\u003e","title":"Usage"},{"content":"mllint can be configured either using a .mllint.yml file or through the project\u0026rsquo;s pyproject.toml. This allows you to:\n selectively disable specific linting rules or categories using their slug define custom linting rules configure specific settings for various linting rules.  See the code snippets and commands provided below for examples of such configuration files.\nCommands To print mllint\u0026rsquo;s current configuration in YAML format, run (optionally providing the path to the project\u0026rsquo;s folder):\nmllint config To print mllint\u0026rsquo;s default configuration in YAML format, run (unless there is a folder called default in the current directory):\nmllint config default To create a .mllint.yml file from mllint\u0026rsquo;s default configuration, run:\nmllint config default -q \u0026gt; .mllint.yml YAML An example .mllint.yml that disables some rules looks as follows:\nrules: disabled: - version-control/code/git - dependency-management/single Similar to the describe command, this also matches partial slugs. So, to disable all rules regarding version controlling data, use version-control/data.\nTOML If no .mllint.yml is found, mllint searches the project\u0026rsquo;s pyproject.toml for a [tool.mllint] section. TOML has a slightly different syntax, but the structure is otherwise the same as the config in the YAML file.\nAn example pyproject.toml configuration of mllint is as follows. Note that it is identical to the YAML example above.\n[tool.mllint.rules] disabled = [\u0026#34;version-control/code/git\u0026#34;, \u0026#34;dependency-management/single\u0026#34;] ","permalink":"http://bvobart.github.io/mllint/docs/configuration/","summary":"mllint can be configured either using a .mllint.yml file or through the project\u0026rsquo;s pyproject.toml. This allows you to:\n selectively disable specific linting rules or categories using their slug define custom linting rules configure specific settings for various linting rules.  See the code snippets and commands provided below for examples of such configuration files.\nCommands To print mllint\u0026rsquo;s current configuration in YAML format, run (optionally providing the path to the project\u0026rsquo;s folder):","title":"Configuration"},{"content":"This category assesses your project\u0026rsquo;s code quality by running several static analysis tools on your project. Static analysis tools analyse your code without actually running it, in an attempt to find potential bugs, refactoring opportunities and/or coding style violations.\nThe linter for this category will check whether your project is using the configured set of code quality linters. mllint supports (and by default requires) the following linters:\n pylint mypy black isort bandit  For your project to be considered to be using a linter\u0026hellip;\n Either there is a configuration file for this linter in the project Or the linter is a dependency of the project (preferably a dev dependency)  You can configure which linters mllint requires your project to use, using the following snippet of YAML in a .mllint.yml configuration file:\ncode-quality: linters: - pylint - mypy - black - isort - bandit or TOML:\n[code-quality] linters = [\u0026#34;pylint\u0026#34;, \u0026#34;mypy\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;isort\u0026#34;, \u0026#34;bandit\u0026#34;] We recommend that you configure each of these linters as you see fit using their respective configuration options. Those will then automatically be picked up as mllint runs them.\n","permalink":"http://bvobart.github.io/mllint/docs/categories/code-quality/","summary":"This category assesses your project\u0026rsquo;s code quality by running several static analysis tools on your project. Static analysis tools analyse your code without actually running it, in an attempt to find potential bugs, refactoring opportunities and/or coding style violations.\nThe linter for this category will check whether your project is using the configured set of code quality linters. mllint supports (and by default requires) the following linters:\n pylint mypy black isort bandit  For your project to be considered to be using a linter\u0026hellip;","title":"Category â€” Code Quality"},{"content":"This category evaluates checks whether your project uses Continuous Integration (CI) and how you are using it.\nContinuous Integration is the practice of automating the integration (merging) of all changes that multiple developers make to a software project. This is done by running an automated process for every commit to your project\u0026rsquo;s Git repository. This process then downloads your project\u0026rsquo;s source code at that commit, builds it, runs the linters configured for the projectâ€”we hope you include mllintâ€”and runs the project\u0026rsquo;s tests against the system.\nThe core idea is that the CI server should be the unbiased arbiter of whether the project\u0026rsquo;s code works after a certain set of changes, while providing a standardised environment to your whole team for verifying that the project truly works as intended. No more \u0026lsquo;but it worked on my machine\u0026rsquo; excuses.\nExplore these sources to learn more about what CI entails:\n WikiPedia - Continuous Integration ThoughtWorks, though a sales pitch, succinctly describes CI and several best practices relating to it, as well as its primary advantages. SE4ML Best Practice - Use Continuous Integration  To learn how to implement CI, see also the description of rule ci/use\nNote: that this category is not fully implemented yet. It may later be expanded with rules on the structure of your CI pipelines (e.g. has stages build, test, deploy, that actually build, test and deploy the project.\n","permalink":"http://bvobart.github.io/mllint/docs/categories/ci/","summary":"This category evaluates checks whether your project uses Continuous Integration (CI) and how you are using it.\nContinuous Integration is the practice of automating the integration (merging) of all changes that multiple developers make to a software project. This is done by running an automated process for every commit to your project\u0026rsquo;s Git repository. This process then downloads your project\u0026rsquo;s source code at that commit, builds it, runs the linters configured for the projectâ€”we hope you include mllintâ€”and runs the project\u0026rsquo;s tests against the system.","title":"Category â€” Continuous Integration"},{"content":"This category enables you to write your own custom evaluation rules for mllint. Custom rules can be useful for enforcing team, company or organisational practices, as well as implementing checks and analyses for how your proprietary / closed-source tools are being used. Custom rules may also be useful for creating \u0026lsquo;plugins\u0026rsquo; to mllint, that implement checks on tools that mllint does not yet have built-in rules for.\nmllint will pick up these custom rules from your configuration and automatically run their checks during its analysis. It is also possible to use the mllint describe command with custom rules. Similarly, mllint list all also lists all custom linting rules.\n To create such a custom rule, write a script or program that checks whether your project adheres to a certain practice and prints a simple YAML or JSON object containing the score for this rule, possibly along with some detail text. Then, add the rule\u0026rsquo;s name, slug, details and run command to your project\u0026rsquo;s mllint config.\nThe following snippet of a YAML mllint configuration is an example of how a custom rule can be configured. See the table below for more details about each of the custom rule definition\u0026rsquo;s properties.\nrules: custom: - name: Project contains a LICENSE file slug: custom/is-licensed details: This rule checks whether the project contains a LICENSE or LICENSE.md file at the project\u0026#39;s root. weight: 1 run: bash ./scripts/mllint/check-license.sh The equivalent configuration in TOML syntax (for pyproject.toml files) is as follows. Multiple of these snippets can be repeated for defining more rules.\n[[tool.mllint.rules.custom]] name = \u0026#34;Project contains a LICENSE file\u0026#34; slug = \u0026#34;custom/is-licensed\u0026#34; details = \u0026#34;This rule checks whether the project contains a LICENSE or LICENSE.md file at the project\u0026#39;s root.\u0026#34; weight = 1.0 run = \u0026#34;bash ./scripts/mllint/check-license.sh\u0026#34;    Property Type Description     name string A short and concise sentence on what this rule expects of a project / what the rule enforces on the project. Feel free to take inspiration from the names given to mllint\u0026rsquo;s built-in rules.   slug string A unique and URL-friendly identifier for each rule. Should only consist of lowercased letters with dashes for spaces, optionally using slashes for categorisation. For custom rule definitions, the recommended convention is for their slugs to always start with custom/   details string A longer, descriptive, Markdown-formatted text that explains the rule in more detail. This text should explain\u0026hellip; 1) what exactly the rule checks; 2) why the rule checks what it checks, i.e., why is this practice important?; and 3) how should a user fix violations of this rule?   weight float The weight of this rule compared to other rules in the same category. This is used for calculating the category score as a weighted average of the scores of all rules. Zero weight means the rule\u0026rsquo;s results will be shown in the report, but won\u0026rsquo;t count for the category score. Note that YAML accepts any number for this property, e.g. 4, but TOML is more strict with typing and requires you to specify a number with a decimal point, e.g. 4.0   run string The command to run for evaluating this rule. This command will be run in the project\u0026rsquo;s root directory. Note that the command will be run using Golang\u0026rsquo;s os/exec package, which \u0026ldquo;intentionally does not invoke the system shell and does not expand any glob patterns or handle other expansions, pipelines, or redirections typically done by shells.\u0026quot; To run shell commands, invoke the shell directly using e.g. bash -c 'your command \u0026amp;\u0026amp; here' or using the example above to execute shell scripts.    The command specified with run is expected to print a simple YAML (or JSON) object with the following structure:\n   Property Type Description     score float The score given to the rule. Must be a number between 0 and 100, i.e., the score is a percentage indicating the degree to which the project adheres to the implemented rule.   details string A Markdown-formatted piece of text that provides details about the given score and what the user can do to fix a violation of this rule. Where applicable, you may also use this to congratulate the user on successful implementation of this rule.    For an example implementation, consider the rule defined in the example configuration above. The script below is a possible implementation of the ./scripts/mllint/check-license.sh script that is referred to by the example.\n#!/bin/bash if [[ -f LICENSE ]] || [[ -f LICENSE.md ]]; then echo \u0026#39;score: 100\u0026#39; else echo \u0026#39;score: 0\u0026#39; echo \u0026#39;details: \u0026#34;Your project is missing a LICENSE. Please be sure to include our [company license file](https://link.to/company/license-file/) in your project.\u0026#34;\u0026#39; fi ","permalink":"http://bvobart.github.io/mllint/docs/categories/custom/","summary":"This category enables you to write your own custom evaluation rules for mllint. Custom rules can be useful for enforcing team, company or organisational practices, as well as implementing checks and analyses for how your proprietary / closed-source tools are being used. Custom rules may also be useful for creating \u0026lsquo;plugins\u0026rsquo; to mllint, that implement checks on tools that mllint does not yet have built-in rules for.\nmllint will pick up these custom rules from your configuration and automatically run their checks during its analysis.","title":"Category â€” Custom Rules"},{"content":"This category assesses your project\u0026rsquo;s data quality.\nIt is not implemented yet. The idea is that this will contain rules on whether you have proper cleaning scripts and may also include dynamic checks on the data that is currently in the repository (e.g. is it complete (not missing values), are types of each value consistent, that sorta stuff. Perhaps with data-linter or tensorflow-data-validation)\n","permalink":"http://bvobart.github.io/mllint/docs/categories/data-quality/","summary":"This category assesses your project\u0026rsquo;s data quality.\nIt is not implemented yet. The idea is that this will contain rules on whether you have proper cleaning scripts and may also include dynamic checks on the data that is currently in the repository (e.g. is it complete (not missing values), are types of each value consistent, that sorta stuff. Perhaps with data-linter or tensorflow-data-validation)","title":"Category â€” Data Quality"},{"content":"This category deals with how your project manages its dependencies: the Python packages that your project uses to make it work, such as scikit-learn, pandas, tensorflow and pytorch.\nProper dependency management, i.e., properly specifying which packages your project uses and which exact versions of those packages are being used, is important for being able to recreate the environment that your project was developed in. This allows other developers, automated deployment systems, or even just yourself, to install exactly those Python packages that you had installed while developing your project. Therefore, there is no risk that they are either not able to run your code due to missing dependencies, or run into unexpected bugs caused by secretly updated dependencies. In engineering terms, this relates to the concept of reproducibility: given the same project at the same revision with the same inputs, the same output should be produced.\nAdditionally, proper dependency management helps with the maintainability of your project. In this case, that means how easy it will be later on to update the packages that your project uses, but also to add new packages, remove old ones. This is especially useful for indirect dependencies, as no-one has or likes to take the time to go through the changelogs of every sub-package you are using to see if it is compatible with all other (sub-)packages.\n","permalink":"http://bvobart.github.io/mllint/docs/categories/dependency-management/","summary":"This category deals with how your project manages its dependencies: the Python packages that your project uses to make it work, such as scikit-learn, pandas, tensorflow and pytorch.\nProper dependency management, i.e., properly specifying which packages your project uses and which exact versions of those packages are being used, is important for being able to recreate the environment that your project was developed in. This allows other developers, automated deployment systems, or even just yourself, to install exactly those Python packages that you had installed while developing your project.","title":"Category â€” Dependency Management"},{"content":"This category evaluates your project\u0026rsquo;s ability to be deployed in the real world.\nIt is not yet implemented, but may contain rules about Dockerfiles and configurability, among others.\nRecommendations:\n SeldonCore - An open source platform to deploy your machine learning models on Kubernetes at massive scale. Seldon handles scaling to thousands of production machine learning models and provides advanced machine learning capabilities out of the box including Advanced Metrics, Request Logging, Explainers, Outlier Detectors, A/B Tests, Canaries and more.  ","permalink":"http://bvobart.github.io/mllint/docs/categories/deployment/","summary":"This category evaluates your project\u0026rsquo;s ability to be deployed in the real world.\nIt is not yet implemented, but may contain rules about Dockerfiles and configurability, among others.\nRecommendations:\n SeldonCore - An open source platform to deploy your machine learning models on Kubernetes at massive scale. Seldon handles scaling to thousands of production machine learning models and provides advanced machine learning capabilities out of the box including Advanced Metrics, Request Logging, Explainers, Outlier Detectors, A/B Tests, Canaries and more.","title":"Category â€” Deployment"},{"content":"This category deals with the file and folder structure of your ML project.\nIt is not implemented yet. Examples of rules you might see here in the future:\n Project keeps its data in the \u0026lsquo;./data\u0026rsquo; folder Project maintains documentation in a \u0026lsquo;./docs\u0026rsquo; folder. Project\u0026rsquo;s source code is kept in a \u0026lsquo;./src\u0026rsquo; folder, or a folder with the same name as the project / package.  ","permalink":"http://bvobart.github.io/mllint/docs/categories/file-structure/","summary":"This category deals with the file and folder structure of your ML project.\nIt is not implemented yet. Examples of rules you might see here in the future:\n Project keeps its data in the \u0026lsquo;./data\u0026rsquo; folder Project maintains documentation in a \u0026lsquo;./docs\u0026rsquo; folder. Project\u0026rsquo;s source code is kept in a \u0026lsquo;./src\u0026rsquo; folder, or a folder with the same name as the project / package.  ","title":"Category â€” File Structure"},{"content":"Testing in the context of Software Engineering refers to the practice of writing automated checks to ensure that something works as intended. Testing ML systems is, however, different from testing traditional software systems. In traditional software systems, humans write all the logic that processes whatever data the system handles, whereas in ML systems, humans provide examples (training data) of what we want the desired behaviour to be and the machine learns the logic required to produce this behaviour.\nProperly testing ML systems is not only limited to testing the output behaviour of the system, but also entails, e.g.:\n ensuring that data preparation is done correctly and consistently ensuring that data featurisation is done correctly and consistent ensuring that the data is fed into the learning process correctly, e.g. testing helper functions ensuring that the learned logic consistently and accurately produces the desired behaviour  This category contains several rules relating to whether and to what degree you are testing the code of your ML project. Per default, mllint expects at least one test file to be implemented in your project (i.e. a Python file starting with test_ or ending with _test.py) and recommends that you have at least 1 test file for every 4 non-test files, though both these targets are configurable. See the default configuration and the description of rule testing/has-tests for more information on how to configure this.\nFor mllint to be able to assess whether your project\u0026rsquo;s tests pass and what coverage these tests achieve, we will not actually run your tests. Instead, we expect you to run your project\u0026rsquo;s tests yourself and provide the filenames to a JUnit-compatible XML test report and a Cobertura-compatible XML coverage report in your project\u0026rsquo;s mllint configuration. See the description of rule testing/pass and testing/coverage for more information on how to generate and configure these.\n Here are some links to interesting blogs that give more in-depth information about different techniques for testing ML systems:\n MadeWithML - Testing ML Systems: Code, Data and Models Jeremy Jordan - Effective testing for machine learning systems   \u0026ldquo;When writing tests for machine learning systems, one must not only test the student (the ML model), but also the teacher (the code that produces the ML model).\u0026rdquo; â€” Bart van Oort (bvobart)\n ","permalink":"http://bvobart.github.io/mllint/docs/categories/testing/","summary":"Testing in the context of Software Engineering refers to the practice of writing automated checks to ensure that something works as intended. Testing ML systems is, however, different from testing traditional software systems. In traditional software systems, humans write all the logic that processes whatever data the system handles, whereas in ML systems, humans provide examples (training data) of what we want the desired behaviour to be and the machine learns the logic required to produce this behaviour.","title":"Category â€” Testing"},{"content":"This category contains rules relating to version controlling the code and data. Version control software allows you to track changes to your project and helps to work collaboratively with other people within the same project. It also allows you to easily return to an earlier version of your project or merge two versions together.\nGit is the ubiquitously used tool for version controlling code, but Git is not very efficient at handling large or binary files. It is therefore not directly possible to use Git to version control data. Since data plays just as important of a role in ML as the code does, mllint will also check how a project manages its data. This can be done with a tool like Data Version Control (DVC).\n","permalink":"http://bvobart.github.io/mllint/docs/categories/version-control/","summary":"This category contains rules relating to version controlling the code and data. Version control software allows you to track changes to your project and helps to work collaboratively with other people within the same project. It also allows you to easily return to an earlier version of your project or merge two versions together.\nGit is the ubiquitously used tool for version controlling code, but Git is not very efficient at handling large or binary files.","title":"Category â€” Version Control"},{"content":"In order for mllint to be able to run the recommended code quality linters, they must be installed in the current environment, i.e. they must be on PATH.\nThis can be done in a variety of ways, such as installing them globally and / or appending to PATH, but a more recommended way is to install them into a virtualenv, then activating this virtual environment and running mllint within it. Poetry and Pipenv do this automatically, simply install them as development dependencies (--dev) and run e.g. poetry shell to open a shell in which to run mllint.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/linters-installed/","summary":"In order for mllint to be able to run the recommended code quality linters, they must be installed in the current environment, i.e. they must be on PATH.\nThis can be done in a variety of ways, such as installing them globally and / or appending to PATH, but a more recommended way is to install them into a virtualenv, then activating this virtual environment and running mllint within it. Poetry and Pipenv do this automatically, simply install them as development dependencies (--dev) and run e.","title":"Rule â€” Code Quality â€” All code quality linters should be installed in the current environment"},{"content":" Bandit is a tool designed to find common security issues in Python code.\n This rule checks whether Bandit finds any security issues in your project.\nFor configuring Bandit\u0026rsquo;s settings, such as which directories to exclude and which rules to enable / disable, create a .banditfile at the root of your project. See Bandit\u0026rsquo;s documentation to learn more.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/bandit/no-issues/","summary":"Bandit is a tool designed to find common security issues in Python code.\n This rule checks whether Bandit finds any security issues in your project.\nFor configuring Bandit\u0026rsquo;s settings, such as which directories to exclude and which rules to enable / disable, create a .banditfile at the root of your project. See Bandit\u0026rsquo;s documentation to learn more.","title":"Rule â€” Code Quality â€” Bandit reports no issues with this project"},{"content":" Black is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters.\n This rule checks whether Black finds any files it would fix in your project.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/black/no-issues/","summary":"Black is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from pycodestyle nagging about formatting. You will save time and mental energy for more important matters.\n This rule checks whether Black finds any files it would fix in your project.","title":"Rule â€” Code Quality â€” Black reports no issues with this project"},{"content":"isort can be configured using several configuration files, of which .isort.cfg and pyproject.toml are preferred, according to isort\u0026rsquo;s documentation. These are both recognised by mllint, although we recommend centralising tool configurations in your project\u0026rsquo;s pyproject.toml\nSince mllint also recommends using Black, you should configure isort to be compatible with Black. This is done by putting the following in your pyproject.toml\n[tool.isort] profile = \u0026#34;black\u0026#34; Links to isorts documentation:\n Supported Config Files Black Compatibility  ","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/isort/is-configured/","summary":"isort can be configured using several configuration files, of which .isort.cfg and pyproject.toml are preferred, according to isort\u0026rsquo;s documentation. These are both recognised by mllint, although we recommend centralising tool configurations in your project\u0026rsquo;s pyproject.toml\nSince mllint also recommends using Black, you should configure isort to be compatible with Black. This is done by putting the following in your pyproject.toml\n[tool.isort] profile = \u0026#34;black\u0026#34; Links to isorts documentation:\n Supported Config Files Black Compatibility  ","title":"Rule â€” Code Quality â€” isort is properly configured"},{"content":" isort is a Python utility / library to sort imports alphabetically, and automatically separated into sections and by type. It provides a command line utility, Python library and plugins for various editors to quickly sort all your imports.\n This rule checks whether isort finds any files it would fix in your project.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/isort/no-issues/","summary":"isort is a Python utility / library to sort imports alphabetically, and automatically separated into sections and by type. It provides a command line utility, Python library and plugins for various editors to quickly sort all your imports.\n This rule checks whether isort finds any files it would fix in your project.","title":"Rule â€” Code Quality â€” isort reports no issues with this project"},{"content":" Mypy is an optional static type checker for Python that aims to combine the benefits of dynamic (or \u0026ldquo;duck\u0026rdquo;) typing and static typing. Mypy combines the expressive power and convenience of Python with a powerful type system and compile-time type checking.\n This rule checks whether Mypy finds any type issues when running it on all Python files in this project.\nPer default, mllint is configured to make Mypy enforce static typing.\nThe score for this rule is determined as a function of the number of messages Mypy returns and the lines of Python code that your project has. In the ideal case, Mypy does not recognise any code smells in your project, in which case the score is 100%. When there is one Mypy issue for every 20 lines of code, then the score is 50%. When there is one Mypy issue for every 10 lines of code, then the score is 0%.\nMore specifically, in pseudocode, score = 100 - 100 * min(1, 10 * number of msgs / lines of code). Note that the measured amount of lines of code includes any non-hidden Python files in the repository, including those that are ignored by Mypy.\nTo learn more about how type-checking works and how to use it in Python, see:\n https://realpython.com/python-type-checking/  ","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/mypy/no-issues/","summary":"Mypy is an optional static type checker for Python that aims to combine the benefits of dynamic (or \u0026ldquo;duck\u0026rdquo;) typing and static typing. Mypy combines the expressive power and convenience of Python with a powerful type system and compile-time type checking.\n This rule checks whether Mypy finds any type issues when running it on all Python files in this project.\nPer default, mllint is configured to make Mypy enforce static typing.","title":"Rule â€” Code Quality â€” Mypy reports no issues with this project"},{"content":"If you have ever seen your code get squiggly coloured underlining while you are writing it, then you\u0026rsquo;ll be familiar with linting. Linting (or \u0026lsquo;static code analysis\u0026rsquo; as it is more formally called) is the process of parsing and analysing source code without running it, in an attempt to find common programming issues.\nSuch issues include type errors and possible buggy operations (e.g. using an undefined variable, or accessing a non-existant field on an object), but can also show opportunities to rewrite and improve (refactor) your code (e.g. use a list comprehension instead of a for-loop, or showing duplicate (copy-pasted) code). Additionally, static code analysis can also help enforce a specific code style to keep the code better readable and understandable. Overall, linting / static code analysis helps ensure the quality and maintainability of your source code.\nPython knows many static analysis tools. We recommend you employ the following linters:\n   Linter Why?     Pylint General code smells: probable bugs, warnings, refactoring opportunities, basic code style, Python programming conventions.   Mypy Type checking   Black Code style   isort Code style: automatically sorts and prettyprints imports.   Bandit Security    This rule will be satisfied, iff for each of these linters:\n Either there is a configuration file for this linter in the project Or the linter is a dependency of the project (preferably a dev dependency)  ","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/use-linters/","summary":"If you have ever seen your code get squiggly coloured underlining while you are writing it, then you\u0026rsquo;ll be familiar with linting. Linting (or \u0026lsquo;static code analysis\u0026rsquo; as it is more formally called) is the process of parsing and analysing source code without running it, in an attempt to find common programming issues.\nSuch issues include type errors and possible buggy operations (e.g. using an undefined variable, or accessing a non-existant field on an object), but can also show opportunities to rewrite and improve (refactor) your code (e.","title":"Rule â€” Code Quality â€” Project should use code quality linters"},{"content":"Pylint has a good default configuration, though there are likely to be rules that you may want to enable, disable or customise for your project. For example, you may want to configure your indentation width, your maximum line length, or configure which files to ignore while linting.\nAdditionally, some IDEs have their own default configuration for these linters, which may only enable a subset of Pylint\u0026rsquo;s rules. For example, VS Code is known to do this. However, those IDEs generally do pick up your project\u0026rsquo;s own Pylint configuration.\nHaving a Pylint configuration in the project also ensures that you, each of your colleages, as well as the CI, use the same linting configuration.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/pylint/is-configured/","summary":"Pylint has a good default configuration, though there are likely to be rules that you may want to enable, disable or customise for your project. For example, you may want to configure your indentation width, your maximum line length, or configure which files to ignore while linting.\nAdditionally, some IDEs have their own default configuration for these linters, which may only enable a subset of Pylint\u0026rsquo;s rules. For example, VS Code is known to do this.","title":"Rule â€” Code Quality â€” Pylint is configured for this project"},{"content":"Pylint is a static analysis tool for finding generic programming errors. This rule checks whether Pylint returns any errors when running it on all Python files in this project.\nThe score for this rule is determined as a function of the number of messages Pylint returns and the lines of Python code that your project has. In the ideal case, Pylint does not recognise any code smells in your project, in which case the score is 100%. When there is one Pylint issue for every 20 lines of code, then the score is 50%. When there is one Pylint issue for every 10 lines of code, then the score is 0%.\nMore specifically, in pseudocode, score = 100 - 100 * min(1, 10 * number of msgs / lines of code).\nNote that the measured amount of lines of code includes any non-hidden Python files in the repository, including those that are ignored by Pylint.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/code-quality/pylint/no-issues/","summary":"Pylint is a static analysis tool for finding generic programming errors. This rule checks whether Pylint returns any errors when running it on all Python files in this project.\nThe score for this rule is determined as a function of the number of messages Pylint returns and the lines of Python code that your project has. In the ideal case, Pylint does not recognise any code smells in your project, in which case the score is 100%.","title":"Rule â€” Code Quality â€” Pylint reports no issues with this project"},{"content":"This rule checks if your project is using Continuous Integration (CI). To learn more about what CI is, does and entails, see the description of category ci\nImplementing CI requires picking a CI provider that will run the automated builds and tests. There are many CI providers available and you will have to make your own decision on which fits you best, but mllint currently recognises four CI providers, namely:\n Azure DevOps Pipelines GitHub Actions Gitlab CI Travis CI  Follow your CI provider\u0026rsquo;s respective \u0026lsquo;Getting Started\u0026rsquo; guide and set your project up with a pipeline to build, test and lint your project.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/ci/use/","summary":"This rule checks if your project is using Continuous Integration (CI). To learn more about what CI is, does and entails, see the description of category ci\nImplementing CI requires picking a CI provider that will run the automated builds and tests. There are many CI providers available and you will have to make your own decision on which fits you best, but mllint currently recognises four CI providers, namely:","title":"Rule â€” Continuous Integration â€” Project uses Continuous Integration (CI)"},{"content":"Development dependencies are dependencies of your project that are only necessary for development purposes, but are not required for your software to actually run. Examples of this are code quality linters, unit testing frameworks and other project analysis tools, including mllint.\nThis rule is only checked when your project uses Poetry or Pipenv, since these support having development dependencies.\nWhen mllint detects one of the following dependencies in your project, but it is not in your development dependencies, then it will fail this rule.\n bandit black coverage darglint dvc flake8 flake8-bandit flake8-bugbear flake8-docstrings flake8-rst-docstrings flakehell isort mccabe mllint mypy pandas-vet pep8-naming poethepoet pre-commit pre-commit-hooks pyflakes Pygments pylama pylint pytest pytest-cov reorder-python-imports safety sphinx sphinx-rtd-theme sphinx-click tox typeguard xdoctest  ","permalink":"http://bvobart.github.io/mllint/docs/rules/dependency-management/use-dev/","summary":"Development dependencies are dependencies of your project that are only necessary for development purposes, but are not required for your software to actually run. Examples of this are code quality linters, unit testing frameworks and other project analysis tools, including mllint.\nThis rule is only checked when your project uses Poetry or Pipenv, since these support having development dependencies.\nWhen mllint detects one of the following dependencies in your project, but it is not in your development dependencies, then it will fail this rule.","title":"Rule â€” Dependency Management â€” Project places its development dependencies in dev-dependencies"},{"content":"Most, if not all, ML projects either implicitly or explicitly depend on external packages such as numpy, scikit-learn, pandas, matplotlib, tensorflow, pytorch, etc..\nWhile you can install these manually and individually onto your local environment with pip install, it is very easy to lose track of which exact packages and versions thereof you\u0026rsquo;ve installed. In turn, that makes it very difficult for your colleagues (or even yourself) to replicate the set of packages that you had installed while developing your project. This could result in your code simply not working due to missing packages or displaying unexpected bugs because of an updated dependency.\nProper dependency management is thus important for the maintainability and reproducibility of your project, yet research on open-source ML projects has shown that very few ML applications actually manage their dependencies correctly. Many use basic requirements.txt files, often generated using pip freeze, but these have a high tendency to include unrelated packages or packages that cannot be resolved from PyPI (Pip\u0026rsquo;s standard package index), are hard to maintain as they have no distinction between run-time dependencies and development-time dependencies, nor direct and indirect dependencies, and may hamper the reproducibility of your ML project by underspecifying their exact versions and checksums. Managing your project\u0026rsquo;s packages with a setup.py file is similarly flawed and thus also not recommended, except if there is a direct need to build your project into a platform-specific Pip package.\nThe Python Packaging User Guide recommends using either Poetry or Pipenv as dependency managers. The recommendation is to use Pipenv if your project is an application and to use Poetry if it is a library or otherwise needs to be built into a Python package.\nIf you\u0026rsquo;re seeing this in a report, it means your project is currently not using a dependency manager, or one that is not recommended.\nLearn more about Poetry and Pipenv using the links below, pick the one that most suits you, your project and your team, then start managing your dependencies with it.\n Poetry Pipenv  ","permalink":"http://bvobart.github.io/mllint/docs/rules/dependency-management/use/","summary":"Most, if not all, ML projects either implicitly or explicitly depend on external packages such as numpy, scikit-learn, pandas, matplotlib, tensorflow, pytorch, etc..\nWhile you can install these manually and individually onto your local environment with pip install, it is very easy to lose track of which exact packages and versions thereof you\u0026rsquo;ve installed. In turn, that makes it very difficult for your colleagues (or even yourself) to replicate the set of packages that you had installed while developing your project.","title":"Rule â€” Dependency Management â€” Project properly keeps track of its dependencies"},{"content":"In most cases, using multiple different dependency managers only creates confusion in your team regarding which manager to install, which to use for installing the project\u0026rsquo;s dependencies, and in what order. It can also be confusing for your team to figure out where a new dependency should be added, or where an existing dependency should be updated (just in one dependency manager (but which one?), or in both?).\nWe therefore recommend using only one dependency manager, preferably either Poetry or Pipenv. Please see the description of rule dependency-management/use for more information.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/dependency-management/single/","summary":"In most cases, using multiple different dependency managers only creates confusion in your team regarding which manager to install, which to use for installing the project\u0026rsquo;s dependencies, and in what order. It can also be confusing for your team to figure out where a new dependency should be added, or where an existing dependency should be updated (just in one dependency manager (but which one?), or in both?).\nWe therefore recommend using only one dependency manager, preferably either Poetry or Pipenv.","title":"Rule â€” Dependency Management â€” Project should only use one dependency manager"},{"content":"Every ML project should have a set of automated tests to assess the quality, consistency and correctness of their application in a repeatable and reproducible manner.\nThis rule checks how many test files your project contains. In accordance with pytest\u0026rsquo;s conventions for Python tests, test files are Python files starting with test_ or ending with _test.py. Per default, mllint expects at least one test file to be implemented in your project (i.e. a Python file starting with test_ or ending with _test.py) and recommends that you have at least 1 test file for every 4 non-test files, though both these targets are configurable.\nIn order to configure different targets for how many tests a project should have, use the following mllint configuration snippet:\ntesting: report: tests-report.xml # JUnit report for rule testing/pass # Specify targets for testing/has-tests. # Both the minimum required amount of tests as well as the desired ratio of tests to other Python files will be checked. targets: # Minimum number of tests expected to be in your project. Default: 1 minimum: 1 # Define a target ratio of Python test files to other Python files in your project. # By default, mllint expects that 20% of all Python files in your project are tests, # i.e., 1 test file is implemented for every 4 other Python files. ratio: tests: 1 other: 4 or equivalent TOML (without the explaining comments):\n[tool.mllint.testing] report = \u0026#34;tests-report.xml\u0026#34; targets = { minimum = 1, ratio = { tests = 1, other = 4 }} ","permalink":"http://bvobart.github.io/mllint/docs/rules/testing/has-tests/","summary":"Every ML project should have a set of automated tests to assess the quality, consistency and correctness of their application in a repeatable and reproducible manner.\nThis rule checks how many test files your project contains. In accordance with pytest\u0026rsquo;s conventions for Python tests, test files are Python files starting with test_ or ending with _test.py. Per default, mllint expects at least one test file to be implemented in your project (i.","title":"Rule â€” Testing â€” Project has automated tests"},{"content":"Of course, the point of having automated tests is to ensure that they pass. While mllint will not run your tests as part of its static analysis, mllint expects you to run these on your own terms and provide a the filenames to a JUnit-compatible XML test report and a Cobertura-compatible XML coverage report in your project\u0026rsquo;s mllint configuration. Specifically for this rule, the JUnit test report is analysed.\nWhen using pytest to run your project\u0026rsquo;s tests, use the --junitxml=\u0026lt;filename\u0026gt; option to generate such a test report, e.g.:\npytest --junitxml=tests-report.xml You can then configure mllint to pick up your test report as follows:\ntesting: report: tests-report.xml # JUnit report for rule testing/pass or equivalent TOML:\n[tool.mllint.testing] report = \u0026#34;tests-report.xml\u0026#34; ","permalink":"http://bvobart.github.io/mllint/docs/rules/testing/pass/","summary":"Of course, the point of having automated tests is to ensure that they pass. While mllint will not run your tests as part of its static analysis, mllint expects you to run these on your own terms and provide a the filenames to a JUnit-compatible XML test report and a Cobertura-compatible XML coverage report in your project\u0026rsquo;s mllint configuration. Specifically for this rule, the JUnit test report is analysed.\nWhen using pytest to run your project\u0026rsquo;s tests, use the --junitxml=\u0026lt;filename\u0026gt; option to generate such a test report, e.","title":"Rule â€” Testing â€” Project passes all of its automated tests"},{"content":"One way of measuring the effectiveness of automated tests, is by measuring how many lines of code are touched while the tests are being executed. This is called test coverage. The idea is that the more lines are being executed by your tests, the more of your code\u0026rsquo;s behaviour is being exercised, thus yielding a greater probability of bugs surfacing and being detected or prevented.\nNote, however, that line test coverage only measures whether a line of code is executed. This does not mean that the result or side-effect of that line\u0026rsquo;s execution is being assessed for correctness.\nAdditionally, one line may cause two different pathways through your application, e.g., an if-statement. When testing one such path, line test coverage will show that the if-statement was covered, yet it does not always show that only one of the possible paths through your application has been exercised. This can especially occur in complex one-line operations. For this use-case, there is also the concept of branch coverage, though mllint currently does not assess this though.\nFurthermore, for testing ML systems, there is also academic discussion as to whether line coverage or branch coverage makes sense, or whether different forms of coverage are required. While mllint currently does not check or support any of these novel forms of test coverage for ML, we are looking for suggestions on what novel forms of ML code coverage should be assessed and how these can be measured.\n While mllint will not run your tests as part of its static analysis, mllint expects you to run these on your own terms and provide a the filenames to a JUnit-compatible XML test report and a Cobertura-compatible XML coverage report in your project\u0026rsquo;s mllint configuration. Specifically for this rule, the Cobertura-compatible coverage report is analysed.\nGenerating a test coverage report with pytest can be done by adding and installing pytest-cov as a development dependency of your project. Then use the following command to run your tests and generate both a test report as well as a coverage report:\npytest --junitxml=tests-report.xml --cov=path_to_package_under_test --cov-report=xml You can then configure mllint to pick up your test report as follows:\ntesting: coverage: report: coverage.xml targets: line: 80 # percent line coverage. Default is 80% or equivalent TOML:\n[tool.mllint.testing.coverage] report = \u0026#34;coverage.xml\u0026#34; targets = { line = 80.0 } # Note: unlike YAML, TOML distinguishes between floats and integers, so be sure to use 80.0 instead of 80 ","permalink":"http://bvobart.github.io/mllint/docs/rules/testing/coverage/","summary":"One way of measuring the effectiveness of automated tests, is by measuring how many lines of code are touched while the tests are being executed. This is called test coverage. The idea is that the more lines are being executed by your tests, the more of your code\u0026rsquo;s behaviour is being exercised, thus yielding a greater probability of bugs surfacing and being detected or prevented.\nNote, however, that line test coverage only measures whether a line of code is executed.","title":"Rule â€” Testing â€” Project provides a test coverage report"},{"content":"In accordance with pytest\u0026rsquo;s conventions for Python tests and recommendations on test layout, test files are Python files starting with test_ or ending with _test.py and should be placed in a folder called tests at the root of your project.\nThis rule therefore simply checks whether all test files in your projects are indeed in this tests folder at the root of your project.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/testing/tests-folder/","summary":"In accordance with pytest\u0026rsquo;s conventions for Python tests and recommendations on test layout, test files are Python files starting with test_ or ending with _test.py and should be placed in a folder called tests at the root of your project.\nThis rule therefore simply checks whether all test files in your projects are indeed in this tests folder at the root of your project.","title":"Rule â€” Testing â€” Tests should be placed in the tests folder"},{"content":"While using DVC to define pipelines in a dvc.yamlfile, DVC maintains a dvc.lock file to record the state of your pipeline(s) and help track its outputs. As with any .lock file, it is highly recommended to commit your dvc.lock to your project\u0026rsquo;s Git repository. Learn more about dvc.lock files here.\nIf you\u0026rsquo;re seeing this in a report, then your project contains a dvc.lock file, but it has not been added to Git. To add and commit dvc.lock to Git, you may use the following commands:\ngit add dvc.lock git commit -m 'Adds dvc.lock file' git push ","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/commit-dvc-lock/","summary":"While using DVC to define pipelines in a dvc.yamlfile, DVC maintains a dvc.lock file to record the state of your pipeline(s) and help track its outputs. As with any .lock file, it is highly recommended to commit your dvc.lock to your project\u0026rsquo;s Git repository. Learn more about dvc.lock files here.\nIf you\u0026rsquo;re seeing this in a report, then your project contains a dvc.lock file, but it has not been added to Git.","title":"Rule â€” Version Control â€” DVC: File 'dvc.lock' should be committed to Git"},{"content":"DVC uses the .dvc folder to keep records of and information about all your DVC-tracked files and where they are hosted. This folder must be committed to your Git repository in order to work with DVC correctly. Learn more about the .dvc directory here.\nIf you\u0026rsquo;re seeing this in a report, then your project\u0026rsquo;s Git repository is not tracking the \u0026lsquo;.dvc\u0026rsquo; folder. To fix this, you may use the following commands:\ngit add .dvc git commit -m 'Adds .dvc folder for Data Version Control' git push ","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/commit-dvc-folder/","summary":"DVC uses the .dvc folder to keep records of and information about all your DVC-tracked files and where they are hosted. This folder must be committed to your Git repository in order to work with DVC correctly. Learn more about the .dvc directory here.\nIf you\u0026rsquo;re seeing this in a report, then your project\u0026rsquo;s Git repository is not tracking the \u0026lsquo;.dvc\u0026rsquo; folder. To fix this, you may use the following commands:","title":"Rule â€” Version Control â€” DVC: Folder '.dvc' should be committed to Git"},{"content":"To be able to use DVC, it must be installed correctly. If you\u0026rsquo;re seeing this as part of anmllintreport, then it means that mllint was unable to find \u0026lsquo;dvc\u0026rsquo; on your PATH. This could either indicate that DVC is not installed in your project, or it is not included on your path.\nSee DVC\u0026rsquo;s installation instructions to learn more about installing DVC, or simply add it to your project as a Pip package, e.g. using poetry add --dev dvc\n","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/dvc-is-installed/","summary":"To be able to use DVC, it must be installed correctly. If you\u0026rsquo;re seeing this as part of anmllintreport, then it means that mllint was unable to find \u0026lsquo;dvc\u0026rsquo; on your PATH. This could either indicate that DVC is not installed in your project, or it is not included on your path.\nSee DVC\u0026rsquo;s installation instructions to learn more about installing DVC, or simply add it to your project as a Pip package, e.","title":"Rule â€” Version Control â€” DVC: Is installed"},{"content":"Similar to code, data should also be version controlled. However, version controlling data cannot be done with Git directly, as Git is not designed to deal with large and / or binary files. Tracking large files directly with Git adds bloat to your repository\u0026rsquo;s Git history, which needs to be downloaded every time your project is cloned.\nFor properly version controlling Data in ML projects, mllint recommends using Data Version Control (DVC). DVC is an open-source version control system for Machine Learning projects. DVC is built to help version your data and make ML models shareable and reproducible. It is designed to handle large files, datasets, ML models, and metrics as well as code. DVC can also help you manage ML experiments by guaranteeing that all files and metrics will be consistent and in the right place to reproduce the experiments, or use it as a baseline for a new iteration.\nInstall DVC (e.g. using poetry add --dev dvc) and run dvc init in your terminal to get started with DVC.\nTo learn more about DVC and how to use it, feel free to check out DVC\u0026rsquo;s documentation and tutorials from these links:\n DVC Documentation DVC Getting Started DVC Installation DVC Use Cases DVC User Guide  Or if you prefer learning from watching videos, DVC has a YouTube channel with several short, useful and informative videos.\n YouTube Channel: DVCorg YouTube Video: Version Control for Data Science Explained in 5 Minutes YouTube Playlist: DVC Basics  ","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/dvc/","summary":"Similar to code, data should also be version controlled. However, version controlling data cannot be done with Git directly, as Git is not designed to deal with large and / or binary files. Tracking large files directly with Git adds bloat to your repository\u0026rsquo;s Git history, which needs to be downloaded every time your project is cloned.\nFor properly version controlling Data in ML projects, mllint recommends using Data Version Control (DVC).","title":"Rule â€” Version Control â€” DVC: Project uses Data Version Control"},{"content":"Using DVC entails tracking changes to your data and models with DVC. If you\u0026rsquo;re seeing this in a report, your project is using DVC, but it is currently not tracking any files with it. Learn more about getting started with data versioning with DVC, or the dvc add command.\nThen, add your datasets and models to DVC by running the command dvc add \u0026lt;files\u0026gt;\nTip: Under the hood, mllint uses the command dvc list . -R --dvc-only in order to see which files DVC is tracking.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/dvc-has-files/","summary":"Using DVC entails tracking changes to your data and models with DVC. If you\u0026rsquo;re seeing this in a report, your project is using DVC, but it is currently not tracking any files with it. Learn more about getting started with data versioning with DVC, or the dvc add command.\nThen, add your datasets and models to DVC by running the command dvc add \u0026lt;files\u0026gt;\nTip: Under the hood, mllint uses the command dvc list .","title":"Rule â€” Version Control â€” DVC: Should be tracking at least one data file"},{"content":"To share your DVC-tracked data with your colleagues and also allow them to interact with your data, DVC should have at least one remote storage configured. If you\u0026rsquo;re seeing this in a report, your project currently has none.\nLearn more about DVC remotes here, then pick your desired remote storage solution, check the documetation for adding remotes and add it as your default remote to DVC using\ndvc remote add -d \u0026lt;name\u0026gt; \u0026lt;url\u0026gt; ","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/data/dvc-has-remote/","summary":"To share your DVC-tracked data with your colleagues and also allow them to interact with your data, DVC should have at least one remote storage configured. If you\u0026rsquo;re seeing this in a report, your project currently has none.\nLearn more about DVC remotes here, then pick your desired remote storage solution, check the documetation for adding remotes and add it as your default remote to DVC using\ndvc remote add -d \u0026lt;name\u0026gt; \u0026lt;url\u0026gt; ","title":"Rule â€” Version Control â€” DVC: Should have at least one remote data storage configured"},{"content":"Git is great for version controlling small, textual files, but not for binary or large files. Tracking large files directly with Git adds bloat to your repository\u0026rsquo;s Git history, which needs to be downloaded every time your project is cloned. Large files should instead be version controlled as Data, e.g. using Git LFS or DVC. See the version-control/data/ rules of mllint for more info about version controlling data.\nTo fix this rule, it is not enough to just remove these large files from your local filesystem, as the files will still exist inside your Git history. Instead, see this StackOverflow answer to learn how to also remove these files from your project\u0026rsquo;s Git history.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/code/git-no-big-files/","summary":"Git is great for version controlling small, textual files, but not for binary or large files. Tracking large files directly with Git adds bloat to your repository\u0026rsquo;s Git history, which needs to be downloaded every time your project is cloned. Large files should instead be version controlled as Data, e.g. using Git LFS or DVC. See the version-control/data/ rules of mllint for more info about version controlling data.\nTo fix this rule, it is not enough to just remove these large files from your local filesystem, as the files will still exist inside your Git history.","title":"Rule â€” Version Control â€” Project should not have any large files in its Git history"},{"content":"The code of any software project should be tracked in version control software. Git is the most widely-used, most popular, free and open-source version controlling tool, designed to handle anything from small projects to extremely large projects such as the Linux kernel.\nTo start using Git, run git init in a terminal at the root of your project. See also Git\u0026rsquo;s documentation for tutorials on how to work with Git.\n","permalink":"http://bvobart.github.io/mllint/docs/rules/version-control/code/git/","summary":"The code of any software project should be tracked in version control software. Git is the most widely-used, most popular, free and open-source version controlling tool, designed to handle anything from small projects to extremely large projects such as the Linux kernel.\nTo start using Git, run git init in a terminal at the root of your project. See also Git\u0026rsquo;s documentation for tutorials on how to work with Git.","title":"Rule â€” Version Control â€” Project uses Git"},{"content":"Something something mllint was the product of my MSc thesis and this is how it came to be :)\n","permalink":"http://bvobart.github.io/mllint/about/","summary":"Something something mllint was the product of my MSc thesis and this is how it came to be :)","title":"About"}]